{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e814f4",
   "metadata": {},
   "source": [
    "# Lecture 3: Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00f769",
   "metadata": {},
   "source": [
    "### Underflow issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3cf94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 1e-10\n",
    "b = 1e-90\n",
    "c = 1e-30\n",
    "d = 5e-130\n",
    "e = 1e-40\n",
    "f = 1e-100\n",
    "a*b*c*d*e*f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b52157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbcf4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-919.4245992851843"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(a) + np.log(b) + np.log(c) + np.log(d) + np.log(e) + np.log(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e3e796",
   "metadata": {},
   "source": [
    "### Review: Defaultdict and Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b7607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98da4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, we'll implement our language model as the defaultdict with a counter\n",
    "lm = defaultdict(Counter) \n",
    "# keys: previous N-1 words \n",
    "# values: Counter dictionaries \n",
    "    #keys: w_n\n",
    "    #values: count of times you saw w_n with the previous N-1 words \n",
    "    \n",
    "#trigram language model \n",
    "lm[('the', 'dog')]['ate'] += 1 \n",
    "lm[('the', 'dog')]['slept'] += 1\n",
    "lm[('the', 'dog')]['ate'] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3008072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm[('the', 'dog')]['ate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a3dc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#helpful because you don't get errors with keys that don't exist \n",
    "lm[('the', 'dog')]['drank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703fc5b",
   "metadata": {},
   "source": [
    "### LM from Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66366f7",
   "metadata": {},
   "source": [
    "#### 1. Load and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2eeed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba12295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the complete works of William Shakespeare \n",
    "# Then Katie manually removed the preamble \n",
    "\n",
    "#https://www.kaggle.com/datasets/kewagbln/shakespeareonline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff224a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_text = open(\"data/t8.shakespeare-remove-preamble.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828ff325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9882831e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1609\\n\\nTHE SONNETS\\n\\nby William Shakespeare\\n\\n\\n\\n                     1\\n  From fairest creatures we desi'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_text[0:100] #first 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b2fd618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xpense of many a vanished sight.\n",
      "  Then can I grieve at grievances foregone,\n",
      "  And heavily from woe to woe tell o'er\n",
      "  The sad account of fore-bemoaned moan,\n",
      "  Which I new pay as if not paid before.\n",
      "    But if the while I think on thee (dear friend)\n",
      "    All losses are restored, and sorrows end.\n",
      "\n",
      "\n",
      "                     31  \n",
      "  Thy bosom is endeared with all hearts,\n",
      "  Which I by lacking have supposed dead,\n",
      "  And there reigns love and all love's loving parts,\n",
      "  And all those friends which I thought buried.\n",
      "  How many a holy and obsequious tear\n",
      "  Hath dear religious love stol'n from mine eye,\n",
      "  As interest of the dead, which now appear,\n",
      "  But things removed that hidden in thee lie.\n",
      "  Thou art the grave where buried love doth live,\n",
      "  Hung with the trophies of my lovers gone,\n",
      "  Who all their parts of me to thee did give,\n",
      "  That due of many, now is thine alone.\n",
      "    Their images I loved, I view in thee,\n",
      "    And thou (all they) hast all the all of me.\n",
      "\n",
      "\n",
      "                     32\n",
      "  If thou survive m\n"
     ]
    }
   ],
   "source": [
    "#look at some of the text  \n",
    "print(shakespeare_text[20000:21000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a462c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple tokenization, just split on any non-alphanumeric character \n",
    "tokens = re.split(r'\\W+', shakespeare_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1efca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens= 927705\n",
      "Total number of word types= 23724\n"
     ]
    }
   ],
   "source": [
    "print('Total number of tokens=', len(tokens))\n",
    "print('Total number of word types=', len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "785c8d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['else', 'this', 'glutton', 'be', 'to', 'eat', 'the', 'world', 's', 'due']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at some of the tokens\n",
    "tokens[105:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d84d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "# List and Tuple are generic types from the typing module that allow you to specify what type \n",
    "# of elements should be inside these collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8ccf7",
   "metadata": {},
   "source": [
    "#### 2. Create n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81b61fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(toks: list, N: int)-> List[tuple]:\n",
    "    \"\"\"\n",
    "    Iterate through the tokens in the order they appear in the corpus \n",
    "    Sliding window of N to create the n-grams\n",
    "    \n",
    "    Returns: list of tuples of n-grams\n",
    "    \n",
    "    Example bigram (N=2) output: \n",
    "        [('else', 'this'),\n",
    "         ('this', 'glutton'),\n",
    "         ('glutton', 'be'),\n",
    "         ('be', 'to'),\n",
    "         ('to', 'eat'),]\n",
    "    \"\"\"\n",
    "    all_ngrams = []\n",
    "    for i in range(len(tokens)-N+1): \n",
    "        ngram = toks[i:i+N]\n",
    "        all_ngrams.append(tuple(ngram))\n",
    "    return all_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18d8e426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('else', 'this'),\n",
       " ('this', 'glutton'),\n",
       " ('glutton', 'be'),\n",
       " ('be', 'to'),\n",
       " ('to', 'eat'),\n",
       " ('eat', 'the'),\n",
       " ('the', 'world'),\n",
       " ('world', 's'),\n",
       " ('s', 'due'),\n",
       " ('due', 'by')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = create_ngrams(tokens, 2)\n",
    "bigrams[105:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e5394e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('else', 'this', 'glutton'),\n",
       " ('this', 'glutton', 'be'),\n",
       " ('glutton', 'be', 'to'),\n",
       " ('be', 'to', 'eat'),\n",
       " ('to', 'eat', 'the'),\n",
       " ('eat', 'the', 'world'),\n",
       " ('the', 'world', 's'),\n",
       " ('world', 's', 'due'),\n",
       " ('s', 'due', 'by'),\n",
       " ('due', 'by', 'the')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = create_ngrams(tokens, 3)\n",
    "trigrams[105:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b4d3e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1871521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('i', 'am'), 1855),\n",
       " (('i', 'll'), 1745),\n",
       " (('of', 'the'), 1715),\n",
       " (('my', 'lord'), 1666),\n",
       " (('in', 'the'), 1643),\n",
       " (('i', 'have'), 1620),\n",
       " (('i', 'will'), 1566),\n",
       " (('to', 'the'), 1430),\n",
       " (('it', 'is'), 1078),\n",
       " (('to', 'be'), 973)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at ranked list\n",
    "topk= 10\n",
    "sorted(bigram_counts.items(), key=lambda kv: -kv[1])[0:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ba48241",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counts = Counter(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "757a510e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('i', 'pray', 'you'), 242),\n",
       " (('so', 'long', 'as'), 234),\n",
       " (('of', 'the', 'complete'), 219),\n",
       " (('the', 'complete', 'works'), 219),\n",
       " (('complete', 'works', 'of'), 219),\n",
       " (('works', 'of', 'william'), 219),\n",
       " (('of', 'william', 'shakespeare'), 219),\n",
       " (('this', 'electronic', 'version'), 218),\n",
       " (('electronic', 'version', 'of'), 218),\n",
       " (('version', 'of', 'the'), 218)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at ranked list\n",
    "topk= 10\n",
    "sorted(trigram_counts.items(), key=lambda kv: -kv[1])[0:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "504d3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities(word2counts: Counter)-> List[tuple]:\n",
    "    \"\"\"\n",
    "    Helper function\n",
    "    \n",
    "    Input: a Counter with \n",
    "        keys = n-grams\n",
    "        values = counts of that n-grams \n",
    "        \n",
    "    Returns: List of (ngram, probability)\n",
    "    \n",
    "    Example: \n",
    "        >>> word2counts = {'too': 1, 'dost': 1, 'resemble': 1, 'grow': 1} \n",
    "        >>> probability_over_all_words(word2counts)\n",
    "        [('too', 0.25), ('dost', 0.25), ('resemble', 0.25), ('grow', 0.25)]\n",
    "    \"\"\"\n",
    "    total_counts = float(sum(word2counts.values()))\n",
    "    word_probs = []\n",
    "    for word, count in word2counts.items():\n",
    "        prob = count/total_counts\n",
    "        word_probs.append((word, prob))\n",
    "    return word_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74d300a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('too', 0.125),\n",
       " ('dost', 0.125),\n",
       " ('resemble', 0.125),\n",
       " ('grow', 0.125),\n",
       " ('prove', 0.125),\n",
       " ('was', 0.125),\n",
       " ('put', 0.125),\n",
       " ('are', 0.125)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2counts = {'too': 1, 'dost': 1, 'resemble': 1, 'grow': 1, 'prove': 1, 'was': 1, 'put': 1, 'are': 1}\n",
    "probabilities(word2counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74916200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lm(tokens: List, N: int) -> dict:\n",
    "    \"\"\"\n",
    "    Returns: Language model dict  \n",
    "        keys = previous N-1 words \n",
    "        values = List of tuples\n",
    "            first item = word w_n \n",
    "            second item = probability w_n given previous N-1 words (keys)\n",
    "            \n",
    "    Example (N=3):  \n",
    "        {('sweet', 'self'):\n",
    "              [('too', 0.25),\n",
    "               ('dost', 0.25),\n",
    "               ('resemble', 0.25),\n",
    "               ('grow', 0.25)]\n",
    "        }\n",
    "    \"\"\"\n",
    "    lm = defaultdict(Counter)\n",
    "    \n",
    "    # get the counts\n",
    "    for i in range(len(tokens)-(N-1)):\n",
    "        previous_words =  tokens[i:i+N-1]\n",
    "        next_word = tokens[i+N-1]\n",
    "        lm[tuple(previous_words)][next_word] += 1\n",
    "        \n",
    "    #turn counts into probabilites \n",
    "    outlm = {previous_words: probabilities(words2count) for previous_words, words2count in lm.items()}\n",
    "    return outlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76e49c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlm = train_lm(tokens, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caccf053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea1a5afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'mine', 'shall'),\n",
       "  [('sum', 0.3333333333333333),\n",
       "   ('be', 0.3333333333333333),\n",
       "   ('give', 0.3333333333333333)]),\n",
       " (('mine', 'shall', 'sum'), [('my', 1.0)]),\n",
       " (('shall', 'sum', 'my'), [('count', 1.0)]),\n",
       " (('sum', 'my', 'count'), [('and', 1.0)]),\n",
       " (('my', 'count', 'and'), [('make', 1.0)]),\n",
       " (('count', 'and', 'make'), [('my', 1.0)]),\n",
       " (('and', 'make', 'my'),\n",
       "  [('old', 0.14285714285714285),\n",
       "   ('wars', 0.14285714285714285),\n",
       "   ('misery', 0.14285714285714285),\n",
       "   ('image', 0.14285714285714285),\n",
       "   ('vouch', 0.14285714285714285),\n",
       "   ('challenge', 0.14285714285714285),\n",
       "   ('seated', 0.14285714285714285)]),\n",
       " (('make', 'my', 'old'), [('excuse', 1.0)]),\n",
       " (('my', 'old', 'excuse'), [('proving', 1.0)]),\n",
       " (('old', 'excuse', 'proving'), [('his', 1.0)]),\n",
       " (('excuse', 'proving', 'his'), [('beauty', 1.0)]),\n",
       " (('proving', 'his', 'beauty'), [('by', 1.0)]),\n",
       " (('his', 'beauty', 'by'), [('succession', 1.0)]),\n",
       " (('beauty', 'by', 'succession'), [('thine', 1.0)]),\n",
       " (('by', 'succession', 'thine'), [('this', 1.0)]),\n",
       " (('succession', 'thine', 'this'), [('were', 1.0)]),\n",
       " (('thine', 'this', 'were'), [('to', 1.0)]),\n",
       " (('this', 'were', 'to'), [('be', 1.0)]),\n",
       " (('were', 'to', 'be'),\n",
       "  [('new', 0.2),\n",
       "   ('bought', 0.2),\n",
       "   ('saved', 0.2),\n",
       "   ('reveng', 0.2),\n",
       "   ('known', 0.2)]),\n",
       " (('to', 'be', 'new'), [('made', 0.5), ('varnish', 0.5)]),\n",
       " (('be', 'new', 'made'), [('when', 1.0)]),\n",
       " (('new', 'made', 'when'), [('thou', 1.0)]),\n",
       " (('made', 'when', 'thou'), [('art', 1.0)]),\n",
       " (('when', 'thou', 'art'),\n",
       "  [('old', 0.14285714285714285),\n",
       "   ('all', 0.07142857142857142),\n",
       "   ('gone', 0.07142857142857142),\n",
       "   ('a', 0.07142857142857142),\n",
       "   ('king', 0.35714285714285715),\n",
       "   ('dead', 0.14285714285714285),\n",
       "   ('timon', 0.07142857142857142),\n",
       "   ('forth', 0.07142857142857142)]),\n",
       " (('thou', 'art', 'old'), [('and', 1.0)]),\n",
       " (('art', 'old', 'and'), [('see', 0.5), ('rich', 0.5)]),\n",
       " (('old', 'and', 'see'), [('thy', 1.0)]),\n",
       " (('and', 'see', 'thy'), [('blood', 0.5), ('master', 0.5)]),\n",
       " (('see', 'thy', 'blood'), [('warm', 1.0)]),\n",
       " (('thy', 'blood', 'warm'), [('when', 1.0)])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just visualize some of the outputs\n",
    "list(outlm.items())[200:230]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324f3cc0",
   "metadata": {},
   "source": [
    "Generation code in Lecture 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1134452",
   "metadata": {},
   "source": [
    "Acknowledgements: \n",
    "- Some of this code was adapted from Yoav Goldberg's [character-level language model](https://nbviewer.org/gist/yoavg/d76121dfde2618422139)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs375] *",
   "language": "python",
   "name": "conda-env-cs375-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e814f4",
   "metadata": {},
   "source": [
    "# Lecture 4: Wraping up Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a5d72f",
   "metadata": {},
   "source": [
    "### Rolling weighted die "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12562d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8e3545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = np.random.choice([1, 2, 3, 4, 5, 6])\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc2f75d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rolling a \"weighted die\"\n",
    "sample = np.random.choice([1, 2, 3, 4, 5, 6], p=[0.5, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad903ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 527, 2: 106, 3: 102, 4: 93, 5: 87, 6: 85})\n"
     ]
    }
   ],
   "source": [
    "counts = Counter()\n",
    "for _ in range(1000): \n",
    "    sample = np.random.choice([1, 2, 3, 4, 5, 6], p=[0.5, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "    counts[sample] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2bcb1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'world': 5023, 'tables': 2984, 'skirts': 1993})\n"
     ]
    }
   ],
   "source": [
    "# How we are going to generate \n",
    "distribution = [('world', 0.7), ('skirts',0.1), ('tables',0.2)]\n",
    "words = [x[0] for x in distribution]\n",
    "probs = [x[1] for x in distribution]\n",
    "\n",
    "count_chosen = Counter()\n",
    "\n",
    "#Simulation with 10,000 trials, see if we get the correct expected values\n",
    "for _ in range(10000): \n",
    "    word = np.random.choice(words, p=probs)\n",
    "    count_chosen[word] +=1 \n",
    "    \n",
    "print(count_chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703fc5b",
   "metadata": {},
   "source": [
    "### LM from Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9083c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from collections import defaultdict, Counter \n",
    "import re \n",
    "import random \n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff224a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_text = open(\"t8.shakespeare-remove-preamble.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a462c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple tokenization, just split on any non-alphanumeric character \n",
    "tokens = re.split(r'\\W+', shakespeare_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "504d3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities(word2counts: Counter)-> List[tuple]:\n",
    "    \"\"\"\n",
    "    Helper function\n",
    "    \n",
    "    Input: a Counter with \n",
    "        keys = n-grams\n",
    "        values = counts of that n-grams \n",
    "        \n",
    "    Returns: List of (ngram, probability)\n",
    "    \n",
    "    Example: \n",
    "        >>> word2counts = {'too': 1, 'dost': 1, 'resemble': 1, 'grow': 1} \n",
    "        >>> probability_over_all_words(word2counts)\n",
    "        [('too', 0.25), ('dost', 0.25), ('resemble', 0.25), ('grow', 0.25)]\n",
    "    \"\"\"\n",
    "    total_counts = float(sum(word2counts.values()))\n",
    "    word_probs = []\n",
    "    for word, count in word2counts.items():\n",
    "        prob = count/total_counts\n",
    "        word_probs.append((word, prob))\n",
    "    return word_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74916200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lm(tokens: List, N: int) -> dict:\n",
    "    \"\"\"\n",
    "    Returns: Language model dict  \n",
    "        keys = previous N-1 words \n",
    "        values = List of tuples\n",
    "            first item = word w_n \n",
    "            second item = probability w_n given previous N-1 words (keys)\n",
    "            \n",
    "    Example (N=3):  \n",
    "        {('sweet', 'self'):\n",
    "              [('too', 0.25),\n",
    "               ('dost', 0.25),\n",
    "               ('resemble', 0.25),\n",
    "               ('grow', 0.25)]\n",
    "        }\n",
    "    \"\"\"\n",
    "    lm = defaultdict(Counter)\n",
    "    \n",
    "    # get the counts\n",
    "    for i in range(len(tokens)-(N-1)):\n",
    "        previous_words =  tokens[i:i+N-1]\n",
    "        next_word = tokens[i+N-1]\n",
    "        lm[tuple(previous_words)][next_word] += 1\n",
    "        \n",
    "    #turn counts into probabilites \n",
    "    outlm = {previous_words: probabilities(words2count) for previous_words, words2count in lm.items()}\n",
    "    return outlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76e49c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlm = train_lm(tokens, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caccf053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea1a5afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('be', 'new', 'made'), [('when', 1.0)]),\n",
       " (('new', 'made', 'when'), [('thou', 1.0)]),\n",
       " (('made', 'when', 'thou'), [('art', 1.0)]),\n",
       " (('when', 'thou', 'art'),\n",
       "  [('old', 0.14285714285714285),\n",
       "   ('all', 0.07142857142857142),\n",
       "   ('gone', 0.07142857142857142),\n",
       "   ('a', 0.07142857142857142),\n",
       "   ('king', 0.35714285714285715),\n",
       "   ('dead', 0.14285714285714285),\n",
       "   ('timon', 0.07142857142857142),\n",
       "   ('forth', 0.07142857142857142)]),\n",
       " (('thou', 'art', 'old'), [('and', 1.0)]),\n",
       " (('art', 'old', 'and'), [('see', 0.5), ('rich', 0.5)]),\n",
       " (('old', 'and', 'see'), [('thy', 1.0)]),\n",
       " (('and', 'see', 'thy'), [('blood', 0.5), ('master', 0.5)]),\n",
       " (('see', 'thy', 'blood'), [('warm', 1.0)]),\n",
       " (('thy', 'blood', 'warm'), [('when', 1.0)])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just visualize some of the outputs\n",
    "list(outlm.items())[220:230]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073288bf",
   "metadata": {},
   "source": [
    "#### 3. Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "058bb88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word(lm: dict, N: int, previous_words: list):\n",
    "    \"\"\"\n",
    "    Generates a single word from the learned language model \n",
    "    \"\"\"\n",
    "    distribution = lm[tuple(previous_words)]\n",
    "    words = [x[0] for x in distribution]\n",
    "    probs = [x[1] for x in distribution]\n",
    "    return np.random.choice(words, p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d2a4e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('world', 0.3333333333333333),\n",
       " ('skirts', 0.3333333333333333),\n",
       " ('tables', 0.3333333333333333)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only three learned options for the next starting word \n",
    "outlm[(\"hath\", \"in\", \"the\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b3b9403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tables'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a couple of times \n",
    "generate_word(outlm, 4, [\"hath\", \"in\", \"the\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b78f2b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lm: dict, N: int, start_grams: list, nwords=100):\n",
    "    \"\"\"\n",
    "    Generates nwords of text given: \n",
    "        - the trained language model (lm)\n",
    "        - the start grams\n",
    "    \"\"\"\n",
    "    assert len(start_grams) == N-1\n",
    "    previous_words = start_grams \n",
    "    out = []\n",
    "    for i in range(nwords):\n",
    "        generated_word = generate_word(lm, N, previous_words)\n",
    "        previous_words = previous_words[1:N-1] + [generated_word]\n",
    "        out.append(generated_word)\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c144130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tables of their thoughts to every ticklish reader set them down on two low stools and sew volumnia i pray'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(outlm, 4, [\"hath\", \"in\", \"the\"], nwords=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1134452",
   "metadata": {},
   "source": [
    "Acknowledgements: \n",
    "- Some of this code was adapted from Yoav Goldberg's [character-level language model](https://nbviewer.org/gist/yoavg/d76121dfde2618422139)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs375] *",
   "language": "python",
   "name": "conda-env-cs375-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
